---
layout: post
title: 日志采集选型分析
category: 日志采集
tags: 
    - 日志
    - 日志采集
    - ELK
    - Flume
description: 简单分析的多个日志采集和分析平台，例如：Flume + HDFS、ELK、Kafka等
---

# 日志采集选型分析

[TOC]

### 日志的数据源有哪些？

| 数据源                                  | 数据源的数据类型<br>【采集方式】 | 业务类型                               |
| --------------------------------------- | -------------------------------- | -------------------------------------- |
| java web log、tomcat、nginx、apache log | txt                              | 软件服务器日志文件、SQL日志            |
| http 接口                               | http                             | 采集机数据服务或其他业务系统的数据服务 |
| 网络设备                                | snmp                             | 管理网络设备                           |
| hdfs、hbasae                            | hdfs、hbasae                     | 已经被存储的历史业务数据               |
| 脚本命令                                | shell、python的命令结果          | 待定                                   |
| 物理机或虚拟机                          | 运行时物理机性能                 | 服务所在主机                           |
| kafka，rabbitmq                         | 消息队列缓存                     | 业务数据在消息队列中                   |
| syslog                                  | tcp、udp                         | 系统日志                               |



### 日志的格式有哪些？

日志的数据类型如上图。

传统的日志格式是面向用户的，所以难以解析。我们要做日志采集和分析平台，就不能随意的输出日志，必须按照一定的格式输出并存储。

常用的日志格式：基于分隔符分割的日志，JSON日志，JavaStack多行日志

常用文本日志的数据格式：https://help.aliyun.com/document_detail/28987.html?spm=a2c4g.11186623.6.583.ryJz66

### 采集日志的框架有哪些？

| 采集框架              |      |      |
| --------------------- | ---- | ---- |
| logstash              |      |      |
| filebeat              |      |      |
| fluentd               |      |      |
| flume                 |      |      |
| 在线日志平台提供的SDK |      |      |



### 日志采集的高性能如何实现？从大数据环境考虑

 采集端：由采集端本身决定，尤其是采集端的缓存策略是基于内存还是文件。可以通过一台机器部署多个采集进程提高采集吞吐量。

接收端：通过集群增加数据传输吞吐量。

消息队列：对于大数据采集，可以通过消息队列提高数据流的稳定性。

### 日志采集的高可用如何实现？从采集端不可用和接收端不可用的情况下考虑

* 采集端不可用：

  | 采集方式                      | 故障类型                                    | 实现高可用                         |
  | ----------------------------- | ------------------------------------------- | ---------------------------------- |
  | agent采集                     | agent死机、网络故障无法连接接收端、进程奔溃 | 实现本地缓存或存储日志采集的偏移量 |
  | ssh、脚本命令、虚拟机性能采集 | 死机                                        | 无法恢复                           |
  | kafka、hdfs类型               | 采集端死机或崩溃                            | 从kafka、hdfs历史数据恢复采集      |

  

* 接收端不可用：

  发送端要自动进行故障转移，将数据发送到没有问题的接收端。

  接收端要提供负载均衡，保证即使存在故障的接收端，也可以提供数据接收服务。

  **这里的接收端，可能是存储端，也可能是中间件接收端，例如Kafka**，总之，都要提供高可用服务。

### 日志存储方案有哪些？从大数据和高可用考虑

* Hdfs 
* Habase
* ElasticSearch

都提供基于数据分片和复制的数据安全方案。

### 日志采集和存储的伸缩性。

| 分析和存储方案 | 伸缩性       |      |
| -------------- | ------------ | ---- |
| hdfs           | 优           |      |
| hbase          | 基于HDFS，优 |      |
| ElasticSearch  | 优           |      |
| kafka          | 优           |      |
|                |              |      |



### 日志分析方案有哪些？优先从大数据和高可用考虑，其他考虑日志分析服务的性能

* ElasticSearch
* Hadoop MapReduce
* Hbase 接口
* 在线的日志平台

### 日志分析，我们的关注点数据，聚焦在哪里？

目前从公司角度来说：

TCRC：虚拟机性能采集和TCRC用户操作日志

容器：容器运行时性能

### 日志采集和分析方案的价值在哪里？从客户和公司角度分析

* 可用性监控【提供实时性能日志和运行日志的分析，或者对接监控平台，提高系统的可用性监控】
* 性能监控
* 故障根源分析【故障溯源】
* 安全审计
* 大数据建模，提供后续数据价值。【人物画像，基于大数据和人工智能的自动化运维】

### 日志分析结果展示方案有哪些？

| 分析平台       | 展示方法                                                     |
| -------------- | ------------------------------------------------------------ |
| ElasticSearch  | Kibana，Graylog：提供强大的日志分析和聚合的视图页面。<br>或者基于Elsearch的接口自定义开发 |
| Hbase          | 提供页面，但是不能作为一个日志分析平台页面。                 |
| 在线的日志平台 | 提供一个完善的分析视图页面                                   |



### 日志是否支持后期二次分析？

基本上，所有的日常存储都是长期大数据存储，所以后续分析应该不是问题。

并且数据存储在ElasticSearch和HDFS可以互相导入，有利于结合使用HDFS数据备份和ElasticSearch数据分析

### 开发自定义日志分析接口

| 框架                                                         | 难度 | 开发                                |
| ------------------------------------------------------------ | ---- | ----------------------------------- |
| HDFS                                                         | 复杂 | 基于MapReduce开发日志分析           |
| Hbase                                                        | 简单 | 基于Hbase客户端开发查询接口         |
| ElasticSearch                                                | 简单 | 基于ElasticSearch客户端开发查询接口 |
| 以上接口都可以做简单的聚合查询，实现sum、ave、min、   rowcount等 |      |                                     |

